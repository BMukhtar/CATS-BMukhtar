{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 22:12:10,068 [WARNING] Found cached dataset json (/Users/make/.cache/huggingface/datasets/json/default-36fa927edf95b427/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "638c114dab2e47efb27c02289fd78439"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 22:12:10,080 [WARNING] Loading cached split indices for dataset at /Users/make/.cache/huggingface/datasets/json/default-36fa927edf95b427/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-af7767bbbd076ab8.arrow and /Users/make/.cache/huggingface/datasets/json/default-36fa927edf95b427/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5a76445b9a03c715.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['labels', 'id', 'sentences'],\n    num_rows: 65118\n})"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configure the root logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "from datasets import load_dataset # huggingface datasets\n",
    "# takes 5GB in huggingface .cache dir, about 727k documents\n",
    "# load only val dataset for quick testing\n",
    "dataset = load_dataset(\"json\", data_files=\"./data/json/val.json\")\n",
    "# split_dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=2357, shuffle=True)\n",
    "# split_dataset['val'] = split_dataset.pop('test')  # rename the test split to val\n",
    "# split_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 22:12:10,627 [INFO] Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2023-05-04 22:12:10,983 [INFO] Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "enc = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "import logging\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizing the splits (num_proc=7):   0%|          | 0/65118 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "252a736b7c4342d49ba7adbd196e42f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_default_device(\"mps\")\n",
    "from datasets import load_dataset\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, huggingface_dataset_name, max_length):\n",
    "        self.dataset = load_dataset(huggingface_dataset_name)\n",
    "        self.tokenizer = SentenceTransformer('all-MiniLM-L6-v2', device=\"mps\")\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        text = item[\"text\"]\n",
    "        label = item[\"label\"]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        return encoding[\"input_ids\"].squeeze(), encoding[\"attention_mask\"].squeeze(), torch.tensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
