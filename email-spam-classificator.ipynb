{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:05.280991Z",
     "end_time": "2023-05-11T18:52:05.608216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  spam\n0  Subject: naturally irresistible your corporate...     1\n1  Subject: the stock trading gunslinger  fanny i...     1\n2  Subject: unbelievable new homes made easy  im ...     1\n3  Subject: 4 color printing special  request add...     1\n4  Subject: do not have money , get software cds ...     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Subject: naturally irresistible your corporate...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Subject: the stock trading gunslinger  fanny i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Subject: unbelievable new homes made easy  im ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Subject: 4 color printing special  request add...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Subject: do not have money , get software cds ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to work on mps\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# read csv to data frame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./emails.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean character count: 1556.7686801675977\n",
      "Max character count: 43952\n"
     ]
    }
   ],
   "source": [
    "# calculate mean length of email body\n",
    "mean_character_count = df['text'].str.len().mean()\n",
    "max_character_count = df['text'].str.len().max()\n",
    "print(f'Mean character count: {mean_character_count}')\n",
    "print(f'Max character count: {max_character_count}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:05.616129Z",
     "end_time": "2023-05-11T18:52:05.620276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:05.622602Z",
     "end_time": "2023-05-11T18:52:07.128889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"mps\")\n",
    "device = get_device()\n",
    "torch.set_default_device(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:07.126277Z",
     "end_time": "2023-05-11T18:52:07.627750Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "text = df.text.values\n",
    "labels = df.spam.values\n",
    "print(type(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:07.628861Z",
     "end_time": "2023-05-11T18:52:07.631547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤═════════════╕\n",
      "│ Tokens       │   Token IDs │\n",
      "╞══════════════╪═════════════╡\n",
      "│ subject      │        3395 │\n",
      "├──────────────┼─────────────┤\n",
      "│ :            │        1024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ today        │        2651 │\n",
      "├──────────────┼─────────────┤\n",
      "│ '            │        1005 │\n",
      "├──────────────┼─────────────┤\n",
      "│ s            │        1055 │\n",
      "├──────────────┼─────────────┤\n",
      "│ idea         │        2801 │\n",
      "├──────────────┼─────────────┤\n",
      "│ dear         │        6203 │\n",
      "├──────────────┼─────────────┤\n",
      "│ mr           │        2720 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ kam          │       27829 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##inski      │       19880 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ attached     │        4987 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ there        │        2045 │\n",
      "├──────────────┼─────────────┤\n",
      "│ are          │        2024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 2            │        1016 │\n",
      "├──────────────┼─────────────┤\n",
      "│ new          │        2047 │\n",
      "├──────────────┼─────────────┤\n",
      "│ samples      │        8168 │\n",
      "├──────────────┼─────────────┤\n",
      "│ of           │        1997 │\n",
      "├──────────────┼─────────────┤\n",
      "│ our          │        2256 │\n",
      "├──────────────┼─────────────┤\n",
      "│ daily        │        3679 │\n",
      "├──────────────┼─────────────┤\n",
      "│ market       │        3006 │\n",
      "├──────────────┼─────────────┤\n",
      "│ research     │        2470 │\n",
      "├──────────────┼─────────────┤\n",
      "│ :            │        1024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ today        │        2651 │\n",
      "├──────────────┼─────────────┤\n",
      "│ '            │        1005 │\n",
      "├──────────────┼─────────────┤\n",
      "│ s            │        1055 │\n",
      "├──────────────┼─────────────┤\n",
      "│ issue        │        3277 │\n",
      "├──────────────┼─────────────┤\n",
      "│ of           │        1997 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ morning      │        2851 │\n",
      "├──────────────┼─────────────┤\n",
      "│ fa           │        6904 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##xes        │       20156 │\n",
      "├──────────────┼─────────────┤\n",
      "│ fixed        │        4964 │\n",
      "├──────────────┼─────────────┤\n",
      "│ income       │        3318 │\n",
      "├──────────────┼─────────────┤\n",
      "│ today        │        2651 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ financial    │        3361 │\n",
      "├──────────────┼─────────────┤\n",
      "│ markets      │        6089 │\n",
      "├──────────────┼─────────────┤\n",
      "│ today        │        2651 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ we           │        2057 │\n",
      "├──────────────┼─────────────┤\n",
      "│ also         │        2036 │\n",
      "├──────────────┼─────────────┤\n",
      "│ have         │        2031 │\n",
      "├──────────────┼─────────────┤\n",
      "│ intra        │       26721 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##day        │       10259 │\n",
      "├──────────────┼─────────────┤\n",
      "│ market       │        3006 │\n",
      "├──────────────┼─────────────┤\n",
      "│ coverage     │        6325 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ on           │        2006 │\n",
      "├──────────────┼─────────────┤\n",
      "│ bloomberg    │       22950 │\n",
      "├──────────────┼─────────────┤\n",
      "│ :            │        1024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ idea         │        2801 │\n",
      "├──────────────┼─────────────┤\n",
      "│ >            │        1028 │\n",
      "├──────────────┼─────────────┤\n",
      "│ go           │        2175 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ reuters      │       26665 │\n",
      "├──────────────┼─────────────┤\n",
      "│ :            │        1024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ id           │        8909 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##us         │        2271 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ bridge       │        2958 │\n",
      "├──────────────┼─────────────┤\n",
      "│ /            │        1013 │\n",
      "├──────────────┼─────────────┤\n",
      "│ tel          │       10093 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##erate      │       22139 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ if           │        2065 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ info         │       18558 │\n",
      "├──────────────┼─────────────┤\n",
      "│ looks        │        3504 │\n",
      "├──────────────┼─────────────┤\n",
      "│ useful       │        6179 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ we           │        2057 │\n",
      "├──────────────┼─────────────┤\n",
      "│ '            │        1005 │\n",
      "├──────────────┼─────────────┤\n",
      "│ d            │        1040 │\n",
      "├──────────────┼─────────────┤\n",
      "│ like         │        2066 │\n",
      "├──────────────┼─────────────┤\n",
      "│ to           │        2000 │\n",
      "├──────────────┼─────────────┤\n",
      "│ arrange      │       13621 │\n",
      "├──────────────┼─────────────┤\n",
      "│ a            │        1037 │\n",
      "├──────────────┼─────────────┤\n",
      "│ free         │        2489 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 30           │        2382 │\n",
      "├──────────────┼─────────────┤\n",
      "│ -            │        1011 │\n",
      "├──────────────┼─────────────┤\n",
      "│ day          │        2154 │\n",
      "├──────────────┼─────────────┤\n",
      "│ trial        │        3979 │\n",
      "├──────────────┼─────────────┤\n",
      "│ for          │        2005 │\n",
      "├──────────────┼─────────────┤\n",
      "│ you          │        2017 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ your         │        2115 │\n",
      "├──────────────┼─────────────┤\n",
      "│ colleagues   │        8628 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ for          │        2005 │\n",
      "├──────────────┼─────────────┤\n",
      "│ your         │        2115 │\n",
      "├──────────────┼─────────────┤\n",
      "│ reference    │        4431 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ please       │        3531 │\n",
      "├──────────────┼─────────────┤\n",
      "│ find         │        2424 │\n",
      "├──────────────┼─────────────┤\n",
      "│ our          │        2256 │\n",
      "├──────────────┼─────────────┤\n",
      "│ price        │        3976 │\n",
      "├──────────────┼─────────────┤\n",
      "│ list         │        2862 │\n",
      "├──────────────┼─────────────┤\n",
      "│ attached     │        4987 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ i            │        1045 │\n",
      "├──────────────┼─────────────┤\n",
      "│ look         │        2298 │\n",
      "├──────────────┼─────────────┤\n",
      "│ forward      │        2830 │\n",
      "├──────────────┼─────────────┤\n",
      "│ to           │        2000 │\n",
      "├──────────────┼─────────────┤\n",
      "│ your         │        2115 │\n",
      "├──────────────┼─────────────┤\n",
      "│ reply        │        7514 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ best         │        2190 │\n",
      "├──────────────┼─────────────┤\n",
      "│ regards      │       12362 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ va           │       12436 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##dim        │       22172 │\n",
      "├──────────────┼─────────────┤\n",
      "│ po           │       13433 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##kh         │       10023 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##le         │        2571 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##b          │        2497 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##kin        │        4939 │\n",
      "├──────────────┼─────────────┤\n",
      "│ account      │        4070 │\n",
      "├──────────────┼─────────────┤\n",
      "│ manager      │        3208 │\n",
      "├──────────────┼─────────────┤\n",
      "│ vp           │       21210 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##ok         │        6559 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##hl         │        7317 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##eb         │       15878 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##kin        │        4939 │\n",
      "├──────────────┼─────────────┤\n",
      "│ @            │        1030 │\n",
      "├──────────────┼─────────────┤\n",
      "│ idea         │        2801 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##gl         │       23296 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##ob         │       16429 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##al         │        2389 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ com          │        4012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ tel          │       10093 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ +            │        1009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 1            │        1015 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 212          │       18164 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 57           │        5401 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##1          │        2487 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 43           │        4724 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##32         │       16703 │\n",
      "├──────────────┼─────────────┤\n",
      "│ fa           │        6904 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##x          │        2595 │\n",
      "├──────────────┼─────────────┤\n",
      "│ +            │        1009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 1            │        1015 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 212          │       18164 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 57           │        5401 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##1          │        2487 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 43           │        4724 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##34         │       22022 │\n",
      "├──────────────┼─────────────┤\n",
      "│ idea         │        2801 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##gl         │       23296 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##ob         │       16429 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##al         │        2389 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ com          │        4012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 140          │        8574 │\n",
      "├──────────────┼─────────────┤\n",
      "│ broadway     │        5934 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 21           │        2538 │\n",
      "├──────────────┼─────────────┤\n",
      "│ st           │        2358 │\n",
      "├──────────────┼─────────────┤\n",
      "│ floor        │        2723 │\n",
      "├──────────────┼─────────────┤\n",
      "│ new          │        2047 │\n",
      "├──────────────┼─────────────┤\n",
      "│ york         │        2259 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ny           │        6396 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 1000         │        6694 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##5          │        2629 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ usa          │        3915 │\n",
      "├──────────────┼─────────────┤\n",
      "│ any          │        2151 │\n",
      "├──────────────┼─────────────┤\n",
      "│ views        │        5328 │\n",
      "├──────────────┼─────────────┤\n",
      "│ expressed    │        5228 │\n",
      "├──────────────┼─────────────┤\n",
      "│ in           │        1999 │\n",
      "├──────────────┼─────────────┤\n",
      "│ this         │        2023 │\n",
      "├──────────────┼─────────────┤\n",
      "│ message      │        4471 │\n",
      "├──────────────┼─────────────┤\n",
      "│ are          │        2024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ those        │        2216 │\n",
      "├──────────────┼─────────────┤\n",
      "│ of           │        1997 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ individual   │        3265 │\n",
      "├──────────────┼─────────────┤\n",
      "│ send         │        4604 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##er         │        2121 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ except       │        3272 │\n",
      "├──────────────┼─────────────┤\n",
      "│ where        │        2073 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ send         │        4604 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##er         │        2121 │\n",
      "├──────────────┼─────────────┤\n",
      "│ specifically │        4919 │\n",
      "├──────────────┼─────────────┤\n",
      "│ states       │        2163 │\n",
      "├──────────────┼─────────────┤\n",
      "│ them         │        2068 │\n",
      "├──────────────┼─────────────┤\n",
      "│ to           │        2000 │\n",
      "├──────────────┼─────────────┤\n",
      "│ be           │        2022 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ views        │        5328 │\n",
      "├──────────────┼─────────────┤\n",
      "│ of           │        1997 │\n",
      "├──────────────┼─────────────┤\n",
      "│ idea         │        2801 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##gl         │       23296 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##ob         │       16429 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##al         │        2389 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ com          │        4012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ this         │        2023 │\n",
      "├──────────────┼─────────────┤\n",
      "│ email        │       10373 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ its          │        2049 │\n",
      "├──────────────┼─────────────┤\n",
      "│ content      │        4180 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ any          │        2151 │\n",
      "├──────────────┼─────────────┤\n",
      "│ files        │        6764 │\n",
      "├──────────────┼─────────────┤\n",
      "│ transmitted  │       11860 │\n",
      "├──────────────┼─────────────┤\n",
      "│ with         │        2007 │\n",
      "├──────────────┼─────────────┤\n",
      "│ it           │        2009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ are          │        2024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ intended     │        3832 │\n",
      "├──────────────┼─────────────┤\n",
      "│ solely       │        9578 │\n",
      "├──────────────┼─────────────┤\n",
      "│ for          │        2005 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ address      │        4769 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##ee         │        4402 │\n",
      "├──────────────┼─────────────┤\n",
      "│ (            │        1006 │\n",
      "├──────────────┼─────────────┤\n",
      "│ s            │        1055 │\n",
      "├──────────────┼─────────────┤\n",
      "│ )            │        1007 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ may          │        2089 │\n",
      "├──────────────┼─────────────┤\n",
      "│ be           │        2022 │\n",
      "├──────────────┼─────────────┤\n",
      "│ legally      │       10142 │\n",
      "├──────────────┼─────────────┤\n",
      "│ privileged   │       21598 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ /            │        1013 │\n",
      "├──────────────┼─────────────┤\n",
      "│ or           │        2030 │\n",
      "├──────────────┼─────────────┤\n",
      "│ confidential │       18777 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ access       │        3229 │\n",
      "├──────────────┼─────────────┤\n",
      "│ by           │        2011 │\n",
      "├──────────────┼─────────────┤\n",
      "│ any          │        2151 │\n",
      "├──────────────┼─────────────┤\n",
      "│ other        │        2060 │\n",
      "├──────────────┼─────────────┤\n",
      "│ party        │        2283 │\n",
      "├──────────────┼─────────────┤\n",
      "│ is           │        2003 │\n",
      "├──────────────┼─────────────┤\n",
      "│ unauthorized │       24641 │\n",
      "├──────────────┼─────────────┤\n",
      "│ without      │        2302 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ express      │        4671 │\n",
      "├──────────────┼─────────────┤\n",
      "│ written      │        2517 │\n",
      "├──────────────┼─────────────┤\n",
      "│ permission   │        6656 │\n",
      "├──────────────┼─────────────┤\n",
      "│ of           │        1997 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ send         │        4604 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##er         │        2121 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ if           │        2065 │\n",
      "├──────────────┼─────────────┤\n",
      "│ you          │        2017 │\n",
      "├──────────────┼─────────────┤\n",
      "│ have         │        2031 │\n",
      "├──────────────┼─────────────┤\n",
      "│ received     │        2363 │\n",
      "├──────────────┼─────────────┤\n",
      "│ this         │        2023 │\n",
      "├──────────────┼─────────────┤\n",
      "│ email        │       10373 │\n",
      "├──────────────┼─────────────┤\n",
      "│ in           │        1999 │\n",
      "├──────────────┼─────────────┤\n",
      "│ error        │        7561 │\n",
      "├──────────────┼─────────────┤\n",
      "│ you          │        2017 │\n",
      "├──────────────┼─────────────┤\n",
      "│ may          │        2089 │\n",
      "├──────────────┼─────────────┤\n",
      "│ not          │        2025 │\n",
      "├──────────────┼─────────────┤\n",
      "│ copy         │        6100 │\n",
      "├──────────────┼─────────────┤\n",
      "│ or           │        2030 │\n",
      "├──────────────┼─────────────┤\n",
      "│ use          │        2224 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ contents     │        8417 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ,            │        1010 │\n",
      "├──────────────┼─────────────┤\n",
      "│ attachment   │       14449 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##s          │        2015 │\n",
      "├──────────────┼─────────────┤\n",
      "│ or           │        2030 │\n",
      "├──────────────┼─────────────┤\n",
      "│ information  │        2592 │\n",
      "├──────────────┼─────────────┤\n",
      "│ in           │        1999 │\n",
      "├──────────────┼─────────────┤\n",
      "│ any          │        2151 │\n",
      "├──────────────┼─────────────┤\n",
      "│ way          │        2126 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ please       │        3531 │\n",
      "├──────────────┼─────────────┤\n",
      "│ destroy      │        6033 │\n",
      "├──────────────┼─────────────┤\n",
      "│ it           │        2009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ and          │        1998 │\n",
      "├──────────────┼─────────────┤\n",
      "│ contact      │        3967 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ send         │        4604 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##er         │        2121 │\n",
      "├──────────────┼─────────────┤\n",
      "│ via          │        3081 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ idea         │        2801 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##gl         │       23296 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##ob         │       16429 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##al         │        2389 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ com          │        4012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ switch       │        6942 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##board      │        6277 │\n",
      "├──────────────┼─────────────┤\n",
      "│ in           │        1999 │\n",
      "├──────────────┼─────────────┤\n",
      "│ one          │        2028 │\n",
      "├──────────────┼─────────────┤\n",
      "│ of           │        1997 │\n",
      "├──────────────┼─────────────┤\n",
      "│ the          │        1996 │\n",
      "├──────────────┼─────────────┤\n",
      "│ following    │        2206 │\n",
      "├──────────────┼─────────────┤\n",
      "│ three        │        2093 │\n",
      "├──────────────┼─────────────┤\n",
      "│ offices      │        4822 │\n",
      "├──────────────┼─────────────┤\n",
      "│ :            │        1024 │\n",
      "├──────────────┼─────────────┤\n",
      "│ new          │        2047 │\n",
      "├──────────────┼─────────────┤\n",
      "│ york         │        2259 │\n",
      "├──────────────┼─────────────┤\n",
      "│ +            │        1009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 1            │        1015 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 212          │       18164 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 57           │        5401 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##1          │        2487 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 43           │        4724 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##32         │       16703 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ;            │        1025 │\n",
      "├──────────────┼─────────────┤\n",
      "│ london       │        2414 │\n",
      "├──────────────┼─────────────┤\n",
      "│ +            │        1009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 44           │        4008 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 171          │       18225 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 430          │       19540 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 288          │       24841 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##8          │        2620 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ;            │        1025 │\n",
      "├──────────────┼─────────────┤\n",
      "│ singapore    │        5264 │\n",
      "├──────────────┼─────────────┤\n",
      "│ +            │        1009 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 65           │        3515 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 332          │       29327 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 07           │        5718 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##00         │        8889 │\n",
      "├──────────────┼─────────────┤\n",
      "│ -            │        1011 │\n",
      "├──────────────┼─────────────┤\n",
      "│ fit          │        4906 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##o          │        2080 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 317          │       26628 │\n",
      "├──────────────┼─────────────┤\n",
      "│ a            │        1037 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ pdf          │       11135 │\n",
      "├──────────────┼─────────────┤\n",
      "│ -            │        1011 │\n",
      "├──────────────┼─────────────┤\n",
      "│ fm           │        4718 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##to         │        3406 │\n",
      "├──────────────┼─────────────┤\n",
      "│ 317          │       26628 │\n",
      "├──────────────┼─────────────┤\n",
      "│ n            │        1050 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ pdf          │       11135 │\n",
      "├──────────────┼─────────────┤\n",
      "│ -            │        1011 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ones         │        3924 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##hee        │       21030 │\n",
      "├──────────────┼─────────────┤\n",
      "│ ##t          │        2102 │\n",
      "├──────────────┼─────────────┤\n",
      "│ .            │        1012 │\n",
      "├──────────────┼─────────────┤\n",
      "│ doc          │        9986 │\n",
      "╘══════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence():\n",
    "    '''Displays the tokens and respective IDs of a random text sample'''\n",
    "    index = random.randint(0, len(text)-1)\n",
    "    table = np.array([tokenizer.tokenize(text[index]),\n",
    "                      tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
    "    print(tabulate(table,\n",
    "                   headers = ['Tokens', 'Token IDs'],\n",
    "                   tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:07.648769Z",
     "end_time": "2023-05-11T18:52:07.664215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'can', \"'\", 't', 'wait', 'to', 'visit', 'the', 'zoo', '!']\n",
      "[1045, 2064, 1005, 1056, 3524, 2000, 3942, 1996, 9201, 999]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[101, 102, 0]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens = tokenizer.tokenize(\"I can't wait to visit the zoo!\")\n",
    "sample_token_ids = tokenizer.convert_tokens_to_ids(sample_tokens)\n",
    "print(sample_tokens)\n",
    "print(sample_token_ids)\n",
    "tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]', '[PAD]'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:07.652250Z",
     "end_time": "2023-05-11T18:52:07.664447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/bm/miniforge3/envs/cats/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    '''\n",
    "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "      - input_ids: list of token ids\n",
    "      - token_type_ids: list of token type ids\n",
    "      - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "    '''\n",
    "    return tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        add_special_tokens = True,\n",
    "        max_length = 32,\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "\n",
    "for sample in text:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids'])\n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:07.656730Z",
     "end_time": "2023-05-11T18:52:23.774350Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5728, 32])\n",
      "torch.Size([5728, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([  101,  3395,  1024,  8100, 27149,  2115,  5971,  4767,  8318,  2003,\n         2428,  2524,  2000, 28667, 14511, 22471,  1037,  2194,  1024,  1996,\n         3006,  2003,  2440,  1997, 10514,  4160,  8449,  9285,  1998,  1996,\n         2592,   102])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(token_id.shape)\n",
    "print(attention_masks.shape)\n",
    "token_id[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:23.775922Z",
     "end_time": "2023-05-11T18:52:23.778039Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels.cpu())\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx],\n",
    "                          attention_masks[train_idx],\n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx],\n",
    "                        attention_masks[val_idx],\n",
    "                        labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_set,\n",
    "    sampler = RandomSampler(train_set),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_set,\n",
    "    sampler = SequentialSampler(val_set),\n",
    "    batch_size = batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:23.779724Z",
     "end_time": "2023-05-11T18:52:23.783827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def b_tp(preds, labels):\n",
    "    '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "    '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "    '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "    '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "    '''\n",
    "    Returns the following metrics:\n",
    "      - accuracy    = (TP + TN) / N\n",
    "      - precision   = TP / (TP + FP)\n",
    "      - recall      = TP / (TP + FN)\n",
    "      - specificity = TN / (TN + FP)\n",
    "    '''\n",
    "    preds = np.argmax(preds, axis = 1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    tp = b_tp(preds, labels)\n",
    "    tn = b_tn(preds, labels)\n",
    "    fp = b_fp(preds, labels)\n",
    "    fn = b_fn(preds, labels)\n",
    "    b_accuracy = (tp + tn) / len(labels)\n",
    "    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "    return b_accuracy, b_precision, b_recall, b_specificity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:23.839555Z",
     "end_time": "2023-05-11T18:52:23.840760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BertForSequenceClassification model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr = 5e-5,\n",
    "                              eps = 1e-08\n",
    "                              )\n",
    "\n",
    "# run on mps\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:23.843994Z",
     "end_time": "2023-05-11T18:52:25.179660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [03:13<03:13, 193.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.1580\n",
      "\t - Validation Accuracy: 0.9783\n",
      "\t - Validation Precision: 0.9103\n",
      "\t - Validation Recall: 0.9917\n",
      "\t - Validation Specificity: 0.9759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [06:25<00:00, 192.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.0351\n",
      "\t - Validation Accuracy: 0.9887\n",
      "\t - Validation Precision: 0.9621\n",
      "\t - Validation Recall: 0.9852\n",
      "\t - Validation Specificity: 0.9918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 2\n",
    "\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "\n",
    "    # ========== Training ==========\n",
    "\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids,\n",
    "                             token_type_ids = None,\n",
    "                             attention_mask = b_input_mask,\n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            eval_output = model(b_input_ids,\n",
    "                                token_type_ids = None,\n",
    "                                attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:52:25.183736Z",
     "end_time": "2023-05-11T18:58:50.362395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:  WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "Predicted Class:  Spam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bm/miniforge3/envs/cats/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_sentence = 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n",
    "\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "    output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "prediction = 'Spam' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Ham'\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ', prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T18:58:50.364657Z",
     "end_time": "2023-05-11T18:58:50.430502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
